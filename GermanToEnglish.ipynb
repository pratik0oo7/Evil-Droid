{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled",
      "provenance": [],
      "collapsed_sections": [
        "Ws2k0jNFd0-a"
      ],
      "authorship_tag": "ABX9TyPjhEZETQg/9ZgGzbcKz4CE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### ***Import Library that required for this Project ❤***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sQ8szUEaamy5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tPDnw0foaTrc"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re\n",
        "from tensorflow import keras\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import load_model\n",
        "from keras import optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "pd.set_option('display.max_colwidth', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***❤ Reading the data that required for this Project ❤***\n",
        "here, our data is text file of the german and English sentence's pairs.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "3DIqm9OWbDB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text(filename):\n",
        "    # open\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all \n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text"
      ],
      "metadata": {
        "id": "jS2y4rN9blni"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a function to split the text into English-German pairs separated by '\\n' and then split these pairs into English sentences and German sentences.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1qpltBTGbt8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_lines(text):\n",
        "    sent = text.strip().split('\\n')\n",
        "    sent = [i.split('\\t') for i in sent]\n",
        "    return sent"
      ],
      "metadata": {
        "id": "lwbQOibkcFZ7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract deu.txt directory\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "jOq0Q7yscTR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_text(\"deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = array(deu_eng)"
      ],
      "metadata": {
        "id": "by75AmxVcW6I"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deu_eng = deu_eng[:50000,:]"
      ],
      "metadata": {
        "id": "XYVD2slvdsZd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***❤ Text Pre-processing that required for this Project ❤***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Ws2k0jNFd0-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at our data, then we will decide which pre-processing steps to adopt.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mTiEUxGreFiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deu_eng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDd_4O8Qd6qI",
        "outputId": "c9b345f0-7d4e-4cb4-c1c5-90bbd74feb3e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['Go.', 'Geh.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
              "       ['Hi.', 'Hallo!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['Hi.', 'Grüß Gott!',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ...,\n",
              "       ['Tom is still sitting.', 'Tom sitzt noch.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2273521 (CK) & #10190706 (wolfgangth)'],\n",
              "       ['Tom is still smoking.', 'Tom raucht immer noch.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2646953 (CK) & #8072723 (Luiaard)'],\n",
              "       ['Tom is still talking.', 'Tom spricht noch.',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2646952 (CK) & #10150806 (wolfgangth)']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove punctuation\n",
        "\n",
        "---\n",
        "\n",
        "convert the lowercase"
      ],
      "metadata": {
        "id": "z8GLKtq7eRrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    \n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
        "\n",
        "deu_eng"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlDIljbLeLwy",
        "outputId": "c7ee5755-c3b1-4ac1-aba9-189c4882104d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['go', 'geh',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'],\n",
              "       ['hi', 'hallo',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #380701 (cburgmer)'],\n",
              "       ['hi', 'grüß gott',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #659813 (Esperantostern)'],\n",
              "       ...,\n",
              "       ['tom is still sitting', 'tom sitzt noch',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2273521 (CK) & #10190706 (wolfgangth)'],\n",
              "       ['tom is still smoking', 'tom raucht immer noch',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2646953 (CK) & #8072723 (Luiaard)'],\n",
              "       ['tom is still talking', 'tom spricht noch',\n",
              "        'CC-BY 2.0 (France) Attribution: tatoeba.org #2646952 (CK) & #10150806 (wolfgangth)']],\n",
              "      dtype='<U537')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Text** to **Sequence** Conversion"
      ],
      "metadata": {
        "id": "iUjwvW3FekZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NTwaYhdCexF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_l = []\n",
        "deu_l = []\n",
        "for i in deu_eng[:,0]:\n",
        "    eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "    deu_l.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "length_df.hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6F4qM2Dce0hT",
        "outputId": "69665e09-cedd-46c6-8c47-deb04a475d2e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f80f1955b50>,\n",
              "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f80f19097d0>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.show()"
      ],
      "metadata": {
        "id": "MTQq32T5e_xp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to build a tokenizer\n",
        "def tokenization(lines):\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer\n",
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "\n",
        "eng_length = 8\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "\n",
        "# prepare Deutch tokenizer\n",
        "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
        "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "deu_length = 8\n",
        "print('Deutch Vocabulary Size: %d' % deu_vocab_size)\n",
        "\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "    # integer encode sequences\n",
        "    seq = tokenizer.texts_to_sequences(lines)\n",
        "    # pad sequences with 0 values\n",
        "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
        "    return seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo0e3gQdfJMM",
        "outputId": "a916ed51-98fa-426e-c45e-d9d13214cb94"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocabulary Size: 6123\n",
            "Deutch Vocabulary Size: 10081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n0_r-MeCfiP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***❤ Modelling the data that required for this Project ❤***"
      ],
      "metadata": {
        "id": "TId3gUzffl8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)\n",
        "\n",
        "# prepare training data\n",
        "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "\n",
        "# prepare validation data\n",
        "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "\n",
        "# build NMT model\n",
        "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(RepeatVector(out_timesteps))\n",
        "    model.add(LSTM(units, return_sequences=True))\n",
        "    model.add(Dense(out_vocab, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "7uyQwEJKfrhR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
        "rms = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweVi6eZgC04",
        "outputId": "f4ed2c76-b322-4ec4-d84b-37a2983137ea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'model.h1.02_03_2022'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
        "          epochs=30, batch_size=512, \n",
        "          validation_split = 0.2,\n",
        "          callbacks=[checkpoint], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SKWL0GqhF5Q",
        "outputId": "45f643e0-458f-4e85-8b2c-03cdceb5020b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.3886\n",
            "Epoch 1: val_loss improved from inf to 2.35162, saving model to model.h1.02_03_2022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_10_layer_call_fn, lstm_cell_10_layer_call_and_return_conditional_losses, lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.02_03_2022/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: model.h1.02_03_2022/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f80e4582410> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f80e720d2d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r63/63 [==============================] - 328s 5s/step - loss: 2.3886 - val_loss: 2.3516\n",
            "Epoch 2/30\n",
            "63/63 [==============================] - ETA: 0s - loss: 2.2226\n",
            "Epoch 2: val_loss improved from 2.35162 to 2.24659, saving model to model.h1.02_03_2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "U8iUvrhOhVTo",
        "outputId": "4c38d60a-f2dc-4b1b-daab-13d3c9812a5b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-314735a9fdda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions"
      ],
      "metadata": {
        "id": "qoD-jXa8lCk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('model.h1.02_03_2022')\n",
        "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))\n",
        "\n",
        "def get_word(n, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == n:\n",
        "            return word\n",
        "    return None\n",
        "\n",
        "# convert predictions into text (English)\n",
        "preds_text = []\n",
        "for i in preds:\n",
        "    temp = []\n",
        "    for j in range(len(i)):\n",
        "        t = get_word(i[j], eng_tokenizer)\n",
        "        if j > 0:\n",
        "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)\n",
        "             \n",
        "        else:\n",
        "            if(t == None):\n",
        "                temp.append('')\n",
        "            else:\n",
        "                temp.append(t)            \n",
        "        \n",
        "    preds_text.append(' '.join(temp))\n",
        "\n",
        "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})\n",
        "\n",
        "pd.set_option('display.max_colwidth', 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "6_gTtfA4lFGr",
        "outputId": "748cab4a-172a-4a52-966d-0c44f3d86405"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-a544d00d59b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.h1.02_03_2022'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df.head(15)\n",
        "pred_df.tail(15)\n",
        "pred_df.sample(15)"
      ],
      "metadata": {
        "id": "D4r8TZk1naAe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}